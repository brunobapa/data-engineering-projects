# Pipeline ETL em Python para Data Warehouse AnalÃ­tico com SQL

Este projeto demonstra a implementaÃ§Ã£o de um pipeline de dados completo, desde a extraÃ§Ã£o de dados brutos atÃ© a carga em um **Data Warehouse** modelado em **Star Schema** (Esquema Estrela), focado em anÃ¡lise de performance de vendas.

## ğŸ§  Contexto do Projeto

O objetivo Ã© simular um cenÃ¡rio real de engenharia de dados onde dados transacionais de vendas sÃ£o processados para permitir anÃ¡lises estratÃ©gicas. O projeto foca em:
- **Modelagem Dimensional**: SeparaÃ§Ã£o clara entre tabelas Fato e DimensÃ£o.
- **Qualidade de Dados**: TransformaÃ§Ãµes para garantir integridade e padronizaÃ§Ã£o.
- **Escalabilidade**: Estrutura modular de cÃ³digo (Extract, Transform, Load).
- **SQL AnalÃ­tico**: Consultas prontas para geraÃ§Ã£o de insights de negÃ³cio.

## ğŸ—ï¸ Arquitetura e Estrutura

O fluxo de dados segue a arquitetura clÃ¡ssica de ETL:
1. **Extract**: SimulaÃ§Ã£o de dados transacionais (CSV).
2. **Transform**: Limpeza, normalizaÃ§Ã£o e criaÃ§Ã£o do modelo dimensional.
3. **Load**: Carga dos dados processados em um banco de dados relacional (SQLite).

### Estrutura do RepositÃ³rio
```text
projeto-dw-analitico/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Dados brutos (Transactions)
â”‚   â””â”€â”€ processed/      # Banco de Dados (Data Warehouse)
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql      # DDL para o esquema estrela
â”‚   â””â”€â”€ queries_analytics.sql  # Consultas para insights
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py      # LÃ³gica de extraÃ§Ã£o/geraÃ§Ã£o
â”‚   â”œâ”€â”€ transform.py    # Modelagem dimensional com Pandas
â”‚   â””â”€â”€ load.py         # Carga no banco de dados
â”œâ”€â”€ main.py             # Orquestrador do pipeline
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â””â”€â”€ README.md           # DocumentaÃ§Ã£o
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**: Linguagem principal para o pipeline.
- **Pandas**: ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados.
- **SQLite**: Banco de dados relacional para o Data Warehouse.
- **SQL**: Modelagem e consultas analÃ­ticas.

## ğŸš€ Como Executar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/brunobapa/data-engineering-projects.git
   ```
2. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```
3. Execute o pipeline:
   ```bash
   python main.py
   ```

## ğŸ“Š Modelagem Dimensional (Star Schema)

O Data Warehouse foi estruturado com as seguintes tabelas:
- **fact_sales**: Registros de transaÃ§Ãµes, preÃ§os e mÃ©tricas.
- **dim_products**: Detalhes dos produtos e categorias.
- **dim_customers**: InformaÃ§Ãµes dos clientes.
- **dim_date**: Atributos temporais (dia, mÃªs, ano, trimestre) para anÃ¡lise de sÃ©ries temporais.

## ğŸ“ˆ Exemplos de Insights Gerados (SQL)

O diretÃ³rio `sql/` contÃ©m consultas para responder perguntas como:
- Qual o faturamento total por categoria de produto?
- Qual a evoluÃ§Ã£o mensal das vendas?
- Quem sÃ£o os top 5 clientes por volume de compras?
- Qual a performance de vendas por localizaÃ§Ã£o de loja?

---
*Projeto desenvolvido para fins de portfÃ³lio de Engenharia de Dados.*
